第一次授课记录
时间：2025-9-22 ～ 2025-9-26

## 学员心得

### I am [ShubinHan](https://github.com/ShubinHan123)

    在这门课上，我学习到了大语言模型（LLM）的核心知识、最新进展以及实践方法，由张军老师、杨建文老师和孙钟恺老师分别授课。通过五个章节的学习，我对大语言模型的原理、发展和应用有了更深入和体系化的理解。
    
    第一章：大语言模型概述（张军老师）
    
    在这一部分，张军老师带我们回顾了大语言模型的基本概念和发展历程。从“什么是语言模型”出发，逐渐延伸到现代大模型的组成模块、常见类型以及解码器的原理。让我印象最深的是老师强调了概率建模的直观意义：一句话的生成并不是神秘的，而是建立在统计规律和条件概率的基础上。同时，通过“hello, world”计算概率的练习，我第一次切身体会到模型如何把语言转化为概率，这种“语言的数学化”给我带来了很强的震撼。
    
    第二章：分词与词向量（张军老师）
    
    在本章中，我对tokenizer 和 embedding 有了更深入理解。分词的作用不仅仅是把句子拆开，更在于为模型构建可处理的最小单位。
    通过练习使用 ernie4.5-0.3b 的 tokenizer 输出 token id，并计算 embedding 的相似度，我更加直观地理解了语义空间的构建：相似的词在向量空间里距离更近。
    
    第三章：注意力机制与 Transformer 结构（张军老师）
    
    这一章是课程的核心，也是理解 LLM 的关键。张军老师详细解释了 attention 的动机 ——解决长距离依赖问题。
    让我收获最大的还有对 并行化优势 的理解。相比 RNN/LSTM 的顺序依赖，Transformer 能够在训练时大幅并行化，这正是支撑当今大模型可行的关键。
    
    第四章：大语言模型的最新进展（杨建文老师）
    
    杨老师的讲课更偏向前沿和应用。他首先带我们对比了最早的 Transformer 结构和 ERNIE4.5 的改进（如 GQA、RoPE、RMSNorm），让我理解到大模型的演进并不是推倒重来，而是在经典架构上不断微调和优化。
    在 MoE 和多模态模型的介绍中，我第一次全面了解了参数规模与计算效率的平衡思路。
    
    补充章节：神经网络与激活函数
    
    这一节主要回顾了最基础的神经网络结构和常见激活函数（如 ReLU、Sigmoid）。虽然内容基础，但在学习 LLM 的过程中重新理解这些知识让我明白：大模型再复杂，也离不开最基本的神经元和非线性激活单元。这种“返璞归真”的感觉让我把握住了整个知识体系的底层逻辑。
    
    第五章：后训练与微调（孙钟恺老师）
    
    孙老师的讲解非常实用，重点介绍了 SFT（监督微调）、DPO（直接偏好优化）、在线 RL 等后训练方法。对我来说最大的启发是：大模型的能力不仅取决于 pre-training，还依赖于后训练阶段的精雕细琢。
    在练习中对比 SFT 与 DPO 的应用场景，我更清晰地认识到：
    1. SFT 更适合“已知答案”的场景（如任务型对话）。
    2. DPO 更适合“偏好对齐”的场景（如与人类价值观一致的回答）。
    这让我理解到产品应用层面的关键：选择合适的后训练方式，才能真正把基础模型变成“好用”的产品模型。
    
    总的来说作为AI产品经理实习生，我最大的收获是：大语言模型不仅是科研问题，更是产品化问题。理解技术原理，才能更好地设计合理的应用场景和交互方式。未来无论是在市过程中模型竞技场的搭建，还是多模态产品的规划，这些课程中的知识都会成为我坚实的底层支撑。

### I am [@YOUR_GITHUB_ID](https://github.com/YOUR_GITHUB_ID)

在这门课上，我学习到了 ... <请在这里补充你都学到了什么知识，或者任何其他你想表达的内容。>

### I am [@YOUR_GITHUB_ID](https://github.com/YOUR_GITHUB_ID)

在这门课上，我学习到了 ... <请在这里补充你都学到了什么知识，或者任何其他你想表达的内容。>
